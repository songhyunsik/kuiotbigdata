{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_20newsgroups\n\u001b[1;32m      9\u001b[0m news \u001b[38;5;241m=\u001b[39m fetch_20newsgroups(subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
=======
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
>>>>>>> origin/main
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "news = fetch_20newsgroups(subset=\"all\")\n",
    "print(news.keys())  # type: ignore"
   ]
<<<<<<< HEAD
=======
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\\nSubject: Pens fans reactions\\nOrganization: Post Office, Carnegie Mellon, Pittsburgh, PA\\nLines: 12\\nNNTP-Posting-Host: po4.andrew.cmu.edu\\n\\n\\n\\nI am sure some bashers of Pens fans are pretty confused about the lack\\nof any kind of posts about the recent Pens massacre of the Devils. Actually,\\nI am  bit puzzled too and a bit relieved. However, I am going to put an end\\nto non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\\nare killing those Devils worse than I thought. Jagr just showed you why\\nhe is much better than his regular season stats. He is also a lot\\nfo fun to watch in the playoffs. Bowman should let JAgr have a lot of\\nfun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\\nregular season game.          PENS RULE!!!\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  3, 17, ...,  3,  1,  7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18846"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: Mamatha Devineni Ratnam &lt;mr47+@andrew.cm...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: mblawson@midway.ecn.uoknor.edu (Matthew ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: hilmi-er@dsv.su.se (Hilmi Eren)\\nSubject...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: guyd@austin.ibm.com (Guy Dawson)\\nSubjec...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: Alexander Samuel McDiarmid &lt;am2o+@andrew...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  target\n",
       "0  From: Mamatha Devineni Ratnam <mr47+@andrew.cm...      10\n",
       "1  From: mblawson@midway.ecn.uoknor.edu (Matthew ...       3\n",
       "2  From: hilmi-er@dsv.su.se (Hilmi Eren)\\nSubject...      17\n",
       "3  From: guyd@austin.ibm.com (Guy Dawson)\\nSubjec...       3\n",
       "4  From: Alexander Samuel McDiarmid <am2o+@andrew...       4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = pd.DataFrame({\"news\": news.data, \"target\": news.target})\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: Mamatha Devineni Ratnam &lt;mr47+@andrew.cm...</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: mblawson@midway.ecn.uoknor.edu (Matthew ...</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: hilmi-er@dsv.su.se (Hilmi Eren)\\nSubject...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: guyd@austin.ibm.com (Guy Dawson)\\nSubjec...</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: Alexander Samuel McDiarmid &lt;am2o+@andrew...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news                    target\n",
       "0  From: Mamatha Devineni Ratnam <mr47+@andrew.cm...          rec.sport.hockey\n",
       "1  From: mblawson@midway.ecn.uoknor.edu (Matthew ...  comp.sys.ibm.pc.hardware\n",
       "2  From: hilmi-er@dsv.su.se (Hilmi Eren)\\nSubject...     talk.politics.mideast\n",
       "3  From: guyd@austin.ibm.com (Guy Dawson)\\nSubjec...  comp.sys.ibm.pc.hardware\n",
       "4  From: Alexander Samuel McDiarmid <am2o+@andrew...     comp.sys.mac.hardware"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dict = {idx: name for idx, name in enumerate(news.target_names)}\n",
    "news_df[\"target\"] = news_df[\"target\"].replace(target_dict)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From Mamatha Devineni Ratnam Subject Pens fans...</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From Matthew B Lawson Subject Which high perfo...</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From hilmi Hilmi Eren Subject Re ARMENIA SAYS ...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From Guy Dawson Subject Re IDE vs SCSI DMA and...</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From Alexander Samuel McDiarmid Subject driver...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news                    target\n",
       "0  From Mamatha Devineni Ratnam Subject Pens fans...          rec.sport.hockey\n",
       "1  From Matthew B Lawson Subject Which high perfo...  comp.sys.ibm.pc.hardware\n",
       "2  From hilmi Hilmi Eren Subject Re ARMENIA SAYS ...     talk.politics.mideast\n",
       "3  From Guy Dawson Subject Re IDE vs SCSI DMA and...  comp.sys.ibm.pc.hardware\n",
       "4  From Alexander Samuel McDiarmid Subject driver...     comp.sys.mac.hardware"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_cleansign(df):\n",
    "    delete_email = re.sub(r\"\\b[\\w\\+]+@[\\w]+.[\\w]+.[\\w]+.[\\w]+\\b\", \" \", df)\n",
    "    delete_number = re.sub(r\"\\b|\\d+|\\b\", \" \", delete_email)\n",
    "    delete_non_word = re.sub(r\"\\b[\\W]+\\b\", \" \", delete_number)\n",
    "    cleaning_result = \" \".join(delete_non_word.split())\n",
    "    return cleaning_result\n",
    "\n",
    "\n",
    "news_df.loc[:, \"news\"] = news_df.loc[:, \"news\"].apply(data_cleansign)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: mblawson@midway.ecn.uoknor.edu (Matthew B Lawson)\n",
      "Subject: Which high-performance VLB video card?\n",
      "Summary: Seek recommendations for VLB video card\n",
      "Nntp-Posting-Host: midway.ecn.uoknor.edu\n",
      "Organization: Engineering Computer Network, University of Oklahoma, Norman, OK, USA\n",
      "Keywords: orchid, stealth, vlb\n",
      "Lines: 21\n",
      "\n",
      "  My brother is in the market for a high-performance video card that supports\n",
      "VESA local bus with 1-2MB RAM.  Does anyone have suggestions/ideas on:\n",
      "\n",
      "  - Diamond Stealth Pro Local Bus\n",
      "\n",
      "  - Orchid Farenheit 1280\n",
      "\n",
      "  - ATI Graphics Ultra Pro\n",
      "\n",
      "  - Any other high-performance VLB card\n",
      "\n",
      "\n",
      "Please post or email.  Thank you!\n",
      "\n",
      "  - Matt\n",
      "\n",
      "-- \n",
      "    |  Matthew B. Lawson <------------> (mblawson@essex.ecn.uoknor.edu)  |   \n",
      "  --+-- \"Now I, Nebuchadnezzar, praise and exalt and glorify the King  --+-- \n",
      "    |   of heaven, because everything he does is right and all his ways  |   \n",
      "    |   are just.\" - Nebuchadnezzar, king of Babylon, 562 B.C.           |   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'From Matthew B Lawson Subject Which high performance VLB video card Summary Seek recommendations for VLB video card Nntp Posting Host midway ecn uoknor edu Organization Engineering Computer Network University of Oklahoma Norman OK USA Keywords orchid stealth vlb Lines My brother is in the market for a high performance video card that supports VESA local bus with MB RAM Does anyone have suggestions ideas on Diamond Stealth Pro Local Bus Orchid Farenheit ATI Graphics Ultra Pro Any other high performance VLB card Please post or email Thank you Matt Matthew B Lawson Now I Nebuchadnezzar praise and exalt and glorify the King of heaven because everything he does is right and all his ways are just Nebuchadnezzar king of Babylon B C . |'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(news.data[1])\n",
    "news_df[\"news\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['look', 'look', 'look']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import stem\n",
    "\n",
    "stmmer = stem.SnowballStemmer(\"english\")\n",
    "sentence = \"looking looks looked\"\n",
    "\n",
    "[stmmer.stem(word) for word in sentence.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('imag', 'imag', 'imagin')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stmmer.stem(\"images\"), stmmer.stem(\"imaging\"), stmmer.stem(\"imagination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "\n",
    "english_stemmer = nltk.stem.SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "english_stemmer = nltk.stem.SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyer(self):\n",
    "        analyzer = super(StemmedTfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "vectorizer = [\n",
    "    CountVectorizer(),\n",
    "    TfidfVectorizer(),\n",
    "    StemmedCountVectorizer(),\n",
    "    StemmedTfidfVectorizer(),\n",
    "]\n",
    "algorithms = [MultinomialNB(), LogisticRegression()]\n",
    "pipelines = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "for case in list(itertools.product(vectorizer, algorithms)):\n",
    "    pipelines.append(make_pipeline(*case))\n",
    "len(pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countVectorizer': {},\n",
       " 'tfidfVectorizer': {},\n",
       " 'stemmedcountvectorizer': {},\n",
       " 'stemmedtfidfvectorizer': {}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_params = [(1, 1), (1, 3)]\n",
    "stopword_params = [\"english\"]\n",
    "lowercase_params = [True, False]\n",
    "max_df_params = np.linspace(0.4, 0.6, num=6)\n",
    "min_df_params = np.linspace(0.0, 0.0, num=1)\n",
    "\n",
    "attributes = {\n",
    "    # \"ngram_range\": ngrams_params,\n",
    "    # \"max_df\": max_df_params,\n",
    "    # \"min_df\": min_df_params,\n",
    "    # \"lowercase\": lowercase_params,\n",
    "    # \"stop_words\": stopword_params,\n",
    "}\n",
    "vectorizer_names = [\n",
    "    \"countVectorizer\",\n",
    "    \"tfidfVectorizer\",\n",
    "    \"stemmedcountvectorizer\",\n",
    "    \"stemmedtfidfvectorizer\",\n",
    "]\n",
    "vectorizer_params_dict = {}\n",
    "\n",
    "for vect_name in vectorizer_names:\n",
    "    vectorizer_params_dict[vect_name] = {}\n",
    "    for key, value in attributes.items():\n",
    "        param_name = vect_name + \"__\" + key\n",
    "        vectorizer_params_dict[vect_name][key] = value\n",
    "vectorizer_params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multinomialnb': {'multinomialnb__alpha': array([1.])},\n",
       " 'logisticRegression': [{'logisticregression__multi_class': ['multinomial'],\n",
       "   'logisticregression__solver': ['saga'],\n",
       "   'logisticregression__penalty': ['l1'],\n",
       "   'logisticregression__C': [0.1, 5.0, 7.0, 10.0, 15.0, 20.0, 100.0]},\n",
       "  {'logisticRegression__multi_class': ['ovr'],\n",
       "   'logisticRegression__solver': ['liblinear'],\n",
       "   'logisticRegression__penalty': ['l2'],\n",
       "   'logisticRegression__C': [0.1, 5.0, 7.0, 10.0, 15.0, 20.0, 100.0]}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_names = [\"multinomialnb\", \"logisticRegression\"]\n",
    "\n",
    "algorithm_params_dict = {}\n",
    "alpha_params = np.linspace(1.0, 1.0, num=1)\n",
    "for i in range(1):\n",
    "    algorithm_params_dict[algorithm_names[i]] = {\n",
    "        algorithm_names[i] + \"__alpha\": alpha_params\n",
    "    }\n",
    "\n",
    "c_params = [0.1, 5.0, 7.0, 10.0, 15.0, 20.0, 100.0]\n",
    "\n",
    "algorithm_params_dict[algorithm_names[1]] = [\n",
    "    {\n",
    "        \"logisticregression__multi_class\": [\"multinomial\"],\n",
    "        \"logisticregression__solver\": [\"saga\"],\n",
    "        \"logisticregression__penalty\": [\"l1\"],\n",
    "        \"logisticregression__C\": c_params,\n",
    "    },\n",
    "    {\n",
    "        \"logisticRegression__multi_class\": [\"ovr\"],\n",
    "        \"logisticRegression__solver\": [\"liblinear\"],\n",
    "        \"logisticRegression__penalty\": [\"l2\"],\n",
    "        \"logisticRegression__C\": c_params,\n",
    "    },\n",
    "]\n",
    "algorithm_params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'multinomialnb__alpha': array([1.])},\n",
       " [{'logisticregression__multi_class': ['multinomial'],\n",
       "   'logisticregression__solver': ['saga'],\n",
       "   'logisticregression__penalty': ['l1'],\n",
       "   'logisticregression__C': [0.1, 5.0, 7.0, 10.0, 15.0, 20.0, 100.0]},\n",
       "  {'logisticregression__multi_class': ['multinomial'],\n",
       "   'logisticregression__solver': ['saga'],\n",
       "   'logisticregression__penalty': ['l1'],\n",
       "   'logisticregression__C': [0.1, 5.0, 7.0, 10.0, 15.0, 20.0, 100.0],\n",
       "   'logisticRegression__multi_class': ['ovr'],\n",
       "   'logisticRegression__solver': ['liblinear'],\n",
       "   'logisticRegression__penalty': ['l2'],\n",
       "   'logisticRegression__C': [0.1, 5.0, 7.0, 10.0, 15.0, 20.0, 100.0]}],\n",
       " {'multinomialnb__alpha': array([1.])},\n",
       " [{'logisticregression__multi_class': ['multinomial'],\n",
       "   'logisticregression__solver': ['saga'],\n",
       "   'logisticregression__penalty': ['l1'],\n",
       "   'logisticregression__C': [0.1, 5.0, 7.0, 10.0, 15.0, 20.0, 100.0]},\n",
       "  {'logisticregression__multi_class': ['multinomial'],\n",
       "   'logisticregression__solver': ['saga'],\n",
       "   'logisticregression__penalty': ['l1'],\n",
       "   'logisticregression__C': [0.1, 5.0, 7.0, 10.0, 15.0, 20.0, 100.0],\n",
       "   'logisticRegression__multi_class': ['ovr'],\n",
       "   'logisticRegression__solver': ['liblinear'],\n",
       "   'logisticRegression__penalty': ['l2'],\n",
       "   'logisticRegression__C': [0.1, 5.0, 7.0, 10.0, 15.0, 20.0, 100.0]}],\n",
       " {'multinomialnb__alpha': array([1.])},\n",
       " [{'logisticregression__multi_class': ['multinomial'],\n",
       "   'logisticregression__solver': ['saga'],\n",
       "   'logisticregression__penalty': ['l1'],\n",
       "   'logisticregression__C': [0.1, 5.0, 7.0, 10.0, 15.0, 20.0, 100.0]},\n",
       "  {'logisticregression__multi_class': ['multinomial'],\n",
       "   'logisticregression__solver': ['saga'],\n",
       "   'logisticregression__penalty': ['l1'],\n",
       "   'logisticregression__C': [0.1, 5.0, 7.0, 10.0, 15.0, 20.0, 100.0],\n",
       "   'logisticRegression__multi_class': ['ovr'],\n",
       "   'logisticRegression__solver': ['liblinear'],\n",
       "   'logisticRegression__penalty': ['l2'],\n",
       "   'logisticRegression__C': [0.1, 5.0, 7.0, 10.0, 15.0, 20.0, 100.0]}],\n",
       " {'multinomialnb__alpha': array([1.])},\n",
       " [{'logisticregression__multi_class': ['multinomial'],\n",
       "   'logisticregression__solver': ['saga'],\n",
       "   'logisticregression__penalty': ['l1'],\n",
       "   'logisticregression__C': [0.1, 5.0, 7.0, 10.0, 15.0, 20.0, 100.0]},\n",
       "  {'logisticregression__multi_class': ['multinomial'],\n",
       "   'logisticregression__solver': ['saga'],\n",
       "   'logisticregression__penalty': ['l1'],\n",
       "   'logisticregression__C': [0.1, 5.0, 7.0, 10.0, 15.0, 20.0, 100.0],\n",
       "   'logisticRegression__multi_class': ['ovr'],\n",
       "   'logisticRegression__solver': ['liblinear'],\n",
       "   'logisticRegression__penalty': ['l2'],\n",
       "   'logisticRegression__C': [0.1, 5.0, 7.0, 10.0, 15.0, 20.0, 100.0]}]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipline_params = []\n",
    "for case in list(itertools.product(vectorizer_names, algorithm_names)):\n",
    "    vect_params = vectorizer_params_dict[case[0]].copy()\n",
    "    algo_params = algorithm_params_dict[case[1]].copy()\n",
    "\n",
    "    if isinstance(algo_params, dict):\n",
    "        vect_params.update(algo_params)\n",
    "        pipline_params.append(vect_params)\n",
    "    else:\n",
    "        temp = []\n",
    "        for param in algo_params:\n",
    "            vect_params.update(param)\n",
    "            temp.append(vect_params.copy())\n",
    "        pipline_params.append(temp)\n",
    "pipline_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('From Mamatha Devineni Ratnam Subject Pens fans reactions Organization Post Office Carnegie Mellon Pittsburgh PA Lines NNTP Posting Host po andrew cmu edu I am sure some bashers of Pens fans are pretty confused about the lack of any kind of posts about the recent Pens massacre of the Devils Actually I am bit puzzled too and a bit relieved However I am going to put an end to non PIttsburghers relief with a bit of praise for the Pens Man they are killing those Devils worse than I thought Jagr just showed you why he is much better than his regular season stats He is also a lot fo fun to watch in the playoffs Bowman should let JAgr have a lot of fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway I was very disappointed not to see the Islanders lose the final regular season game PENS RULE !!!',\n",
       " 'rec.sport.hockey',\n",
       " 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "x_data = news_df.loc[:, \"news\"].tolist()\n",
    "y_data = news_df[\"target\"].tolist()\n",
    "y = LabelEncoder().fit_transform(y_data)\n",
    "x_data[0], y_data[0], y[0]  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs_estimator GridSearchCV(cv=5,\n",
      "             estimator=Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
      "                                       ('multinomialnb', MultinomialNB())]),\n",
      "             n_jobs=-1, param_grid={'multinomialnb__alpha': array([1.])},\n",
      "             refit='accuracy', scoring=['accuracy'], verbose=1) fitting\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "gs_estimator GridSearchCV(cv=5,\n",
      "             estimator=Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
      "                                       ('logisticregression',\n",
      "                                        LogisticRegression())]),\n",
      "             n_jobs=-1,\n",
      "             param_grid=[{'logisticregression__C': [0.1, 5.0, 7.0, 10.0, 15.0,\n",
      "                                                    20.0, 100.0],\n",
      "                          'logisticregression__multi_class': ['multinomial'],\n",
      "                          'logisticregression__penalty': ['l1'],\n",
      "                          'logisticregression__solver': ['saga']},\n",
      "                         {'logisticRegr...\n",
      "                          'logisticRegression__multi_class': ['ovr'],\n",
      "                          'logisticRegression__penalty': ['l2'],\n",
      "                          'logisticRegression__solver': ['liblinear'],\n",
      "                          'logisticregression__C': [0.1, 5.0, 7.0, 10.0, 15.0,\n",
      "                                                    20.0, 100.0],\n",
      "                          'logisticregression__multi_class': ['multinomial'],\n",
      "                          'logisticregression__penalty': ['l1'],\n",
      "                          'logisticregression__solver': ['saga']}],\n",
      "             refit='accuracy', scoring=['accuracy'], verbose=1) fitting\n",
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/songhyunsik/miniconda3/envs/my_project/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/songhyunsik/miniconda3/envs/my_project/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/songhyunsik/miniconda3/envs/my_project/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/songhyunsik/miniconda3/envs/my_project/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/songhyunsik/miniconda3/envs/my_project/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "scoring = [\"accuracy\"]\n",
    "estimator_results = []\n",
    "for idx, (estimator, params) in enumerate(zip(pipelines, pipline_params)):\n",
    "    n_jobs = -1\n",
    "    gs_estimator = GridSearchCV(\n",
    "        refit=\"accuracy\",\n",
    "        estimator=estimator,\n",
    "        param_grid=params,\n",
    "        scoring=scoring,\n",
    "        cv=5,\n",
    "        verbose=1,\n",
    "        n_jobs=n_jobs,\n",
    "    )\n",
    "    print(f\"gs_estimator {gs_estimator} fitting\")\n",
    "\n",
    "    gs_estimator.fit(x_data, y)\n",
    "    estimator_results.append(gs_estimator)"
   ]
>>>>>>> origin/main
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.12.3"
=======
   "version": "3.10.14"
>>>>>>> origin/main
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
